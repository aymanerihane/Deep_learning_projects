{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 89,
      "metadata": {
        "id": "Ek_azYDeLeM1"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Dense, Dropout, Flatten\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "import mediapipe as mp\n",
        "import cv2\n",
        "import numpy as np\n",
        "from collections import deque\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.metrics import confusion_matrix, classification_report\n",
        "import pandas as pd\n",
        "import os\n",
        "from tensorflow.keras.models import load_model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 90,
      "metadata": {
        "id": "pw-zkxryLeM4"
      },
      "outputs": [],
      "source": [
        "# Expressions labels\n",
        "expressions = [\"anger\", \"disgust\", \"fear\", \"happy\", \"sad\", \"surprise\", \"neutral\"]\n",
        "train_data_dir = '/content/Dataset/train/'\n",
        "test_data_dir = '/content/Dataset/test/'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 91,
      "metadata": {
        "id": "2WsY27kbLeM5"
      },
      "outputs": [],
      "source": [
        "# Moving window for smoothing predictions\n",
        "PREDICTION_WINDOW = deque(maxlen=5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 92,
      "metadata": {
        "id": "bVT4TpCBLeM6"
      },
      "outputs": [],
      "source": [
        "# Initialize MediaPipe Face Mesh\n",
        "mp_face_mesh = mp.solutions.face_mesh\n",
        "face_mesh = mp_face_mesh.FaceMesh(\n",
        "    static_image_mode=False, max_num_faces=5, min_detection_confidence=0.5\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 93,
      "metadata": {
        "id": "Gxdy5omILeM7"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.applications import VGG16\n",
        "from tensorflow.keras.layers import GlobalAveragePooling2D\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.applications import VGG16, VGG19\n",
        "\n",
        "\n",
        "def build_model(type):\n",
        "    \"\"\"Build the CNN model.\"\"\"\n",
        "    #  Load VGG19 with pretrained ImageNet weights\n",
        "    if type == 'vgg16':\n",
        "        base_model = VGG16(weights='imagenet', include_top=False, input_shape=(48, 48, 3))\n",
        "    else:\n",
        "        base_model = VGG19(weights='imagenet', include_top=False, input_shape=(48, 48, 3))\n",
        "\n",
        "\n",
        "    # Freeze the base layers\n",
        "    for layer in base_model.layers:\n",
        "        layer.trainable = False\n",
        "\n",
        "    # Add custom classification head\n",
        "    x = GlobalAveragePooling2D()(base_model.output)\n",
        "    x = Dense(256, activation='relu')(x)\n",
        "    output = Dense(7, activation='softmax')(x)  # Example: 10 classes\n",
        "\n",
        "    # Create new model\n",
        "    model = Model(inputs=base_model.input, outputs=output)\n",
        "    model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "    return model\n",
        "# build_model()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def train_model(tp,model, train_dir, test_dir, epochs=50):\n",
        "    \"\"\"Train the model with given data.\"\"\"\n",
        "    # Data augmentation\n",
        "    train_datagen = ImageDataGenerator(\n",
        "        rescale=1. / 255,\n",
        "        rotation_range=30,\n",
        "        shear_range=0.3,\n",
        "        zoom_range=0.3,\n",
        "        width_shift_range=0.2,\n",
        "        height_shift_range=0.2,\n",
        "        horizontal_flip=True,\n",
        "        fill_mode=\"nearest\",\n",
        "    )\n",
        "\n",
        "    test_datagen = ImageDataGenerator(rescale=1. / 255)\n",
        "\n",
        "    train_generator = train_datagen.flow_from_directory(\n",
        "        train_data_dir,\n",
        "        color_mode=\"rgb\",\n",
        "        target_size=(48, 48),\n",
        "        batch_size=32,\n",
        "        class_mode=\"categorical\",\n",
        "        shuffle = True\n",
        "    )\n",
        "    validation_generator = test_datagen.flow_from_directory(\n",
        "        test_data_dir,\n",
        "        color_mode=\"rgb\",\n",
        "        target_size=(48,48),\n",
        "        batch_size=32,\n",
        "        class_mode=\"categorical\",\n",
        "        shuffle = True\n",
        "    )\n",
        "\n",
        "    num_train_imgs = 0\n",
        "    for root, dirs, files in os.walk(train_data_dir):\n",
        "        num_train_imgs += len(files)\n",
        "    num_test_imgs = 0\n",
        "    for root, dirs, files in os.walk(test_data_dir):\n",
        "        num_test_imgs += len(files)\n",
        "\n",
        "    print(num_train_imgs)\n",
        "    print(num_test_imgs)\n",
        "\n",
        "    history = model.fit(\n",
        "        train_generator,\n",
        "        steps_per_epoch=num_train_imgs // 32,\n",
        "        epochs=epochs,\n",
        "        validation_data=validation_generator,\n",
        "        validation_steps=num_test_imgs // 32,\n",
        "\n",
        "    )\n",
        "\n",
        "    model.save(f\"model_{tp}.h5\")\n",
        "\n",
        "    return history"
      ],
      "metadata": {
        "id": "qhYoXg8ZOE-s"
      },
      "execution_count": 94,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 95,
      "metadata": {
        "id": "gD0iish2LeM_"
      },
      "outputs": [],
      "source": [
        "def preprocess_face(face_img):\n",
        "    \"\"\"Preprocess a face image for prediction.\"\"\"\n",
        "    gray = cv2.cvtColor(face_img, cv2.COLOR_BGR2GRAY)\n",
        "    resized = cv2.resize(gray, (48, 48))\n",
        "    normalized = resized / 255.0\n",
        "    return normalized.reshape(1, 48, 48, 1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 96,
      "metadata": {
        "id": "0gruQbXBLeNA"
      },
      "outputs": [],
      "source": [
        "def detect_expression(frame, model):\n",
        "    \"\"\"Detect facial expression in a video frame.\"\"\"\n",
        "    height, width, _ = frame.shape\n",
        "    rgb_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
        "    results = face_mesh.process(rgb_frame)\n",
        "\n",
        "    if results.multi_face_landmarks:\n",
        "        for face_landmarks in results.multi_face_landmarks:\n",
        "            x_min = y_min = float(\"inf\")\n",
        "            x_max = y_max = float(\"-inf\")\n",
        "\n",
        "            for landmark in face_landmarks.landmark:\n",
        "                x, y = int(landmark.x * width), int(landmark.y * height)\n",
        "                x_min = min(x_min, x)\n",
        "                x_max = max(x_max, x)\n",
        "                y_min = min(y_min, y)\n",
        "                y_max = max(y_max, y)\n",
        "\n",
        "            padding = 20\n",
        "            x_min = max(0, x_min - padding)\n",
        "            y_min = max(0, y_min - padding)\n",
        "            x_max = min(width, x_max + padding)\n",
        "            y_max = min(height, y_max + padding)\n",
        "\n",
        "            face = frame[y_min:y_max, x_min:x_max]\n",
        "            if face.size == 0:\n",
        "                continue\n",
        "\n",
        "            processed_face = preprocess_face(face)\n",
        "            prediction = model.predict(processed_face)[0]\n",
        "            PREDICTION_WINDOW.append(prediction)\n",
        "\n",
        "            avg_prediction = np.mean(PREDICTION_WINDOW, axis=0)\n",
        "            expression = expressions[np.argmax(avg_prediction)]\n",
        "            confidence = float(avg_prediction.max())\n",
        "\n",
        "            cv2.rectangle(frame, (x_min, y_min), (x_max, y_max), (0, 255, 0), 2)\n",
        "            cv2.putText(\n",
        "                frame,\n",
        "                f\"{expression} ({confidence:.2f})\",\n",
        "                (x_min, y_min - 10),\n",
        "                cv2.FONT_HERSHEY_SIMPLEX,\n",
        "                0.9,\n",
        "                (0, 255, 0),\n",
        "                2,\n",
        "            )\n",
        "\n",
        "    return frame"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 97,
      "metadata": {
        "id": "MkudQH-5LeNB"
      },
      "outputs": [],
      "source": [
        "def run_realtime(model):\n",
        "    \"\"\"Run real-time facial expression detection.\"\"\"\n",
        "    cap = cv2.VideoCapture(0)\n",
        "    while True:\n",
        "        ret, frame = cap.read()\n",
        "        if not ret:\n",
        "            break\n",
        "\n",
        "        frame = cv2.flip(frame, 1)\n",
        "        processed_frame = detect_expression(frame, model)\n",
        "\n",
        "        cv2.imshow(\"Facial Expression Detection\", processed_frame)\n",
        "        if cv2.waitKey(1) & 0xFF == ord(\"q\"):\n",
        "            break\n",
        "\n",
        "    cap.release()\n",
        "    cv2.destroyAllWindows()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 98,
      "metadata": {
        "id": "3PYYVmzFLeNC"
      },
      "outputs": [],
      "source": [
        "def evaluate_model(model, test_dir, history):\n",
        "    \"\"\"Evaluate the model and visualize the results.\"\"\"\n",
        "    test_datagen = ImageDataGenerator(rescale=1.0 / 255)\n",
        "    test_generator = test_datagen.flow_from_directory(\n",
        "        test_dir,\n",
        "        target_size=(48, 48),\n",
        "        batch_size=32,\n",
        "        class_mode=\"categorical\",\n",
        "        color_mode=\"rgb\",\n",
        "        shuffle=False,\n",
        "    )\n",
        "\n",
        "    # Get predictions and calculate metrics\n",
        "    predictions = model.predict(test_generator)\n",
        "    true_labels = test_generator.classes\n",
        "    predicted_labels = np.argmax(predictions, axis=1)\n",
        "\n",
        "    cm = confusion_matrix(true_labels, predicted_labels)\n",
        "    report = classification_report(\n",
        "        true_labels, predicted_labels, target_names=expressions\n",
        "    )\n",
        "    accuracy = np.sum(true_labels == predicted_labels) / len(true_labels)\n",
        "\n",
        "    print(f\"Overall Accuracy: {accuracy * 100:.2f}%\")\n",
        "    print(\"\\nClassification Report:\")\n",
        "    print(report)\n",
        "\n",
        "    # Plot Confusion Matrix\n",
        "    plt.figure(figsize=(10, 8))\n",
        "    sns.heatmap(\n",
        "        cm,\n",
        "        annot=True,\n",
        "        fmt=\"d\",\n",
        "        cmap=\"Blues\",\n",
        "        xticklabels=expressions,\n",
        "        yticklabels=expressions,\n",
        "    )\n",
        "    plt.title(\"Confusion Matrix\")\n",
        "    plt.xlabel(\"Predicted\")\n",
        "    plt.ylabel(\"True\")\n",
        "    plt.show()\n",
        "\n",
        "    # Plot Accuracy and Loss over Epochs\n",
        "    plt.figure(figsize=(12, 4))\n",
        "\n",
        "    # Plot Accuracy\n",
        "    plt.subplot(1, 2, 1)\n",
        "    plt.plot(history.history['accuracy'], label='Training Accuracy')\n",
        "    plt.plot(history.history['val_accuracy'], label='Validation Accuracy')\n",
        "    plt.title('Accuracy Over Epochs')\n",
        "    plt.xlabel('Epochs')\n",
        "    plt.ylabel('Accuracy')\n",
        "    plt.legend()\n",
        "\n",
        "    # Plot Loss\n",
        "    plt.subplot(1, 2, 2)\n",
        "    plt.plot(history.history['loss'], label='Training Loss')\n",
        "    plt.plot(history.history['val_loss'], label='Validation Loss')\n",
        "    plt.title('Loss Over Epochs')\n",
        "    plt.xlabel('Epochs')\n",
        "    plt.ylabel('Loss')\n",
        "    plt.legend()\n",
        "\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 99,
      "metadata": {
        "id": "OJLtUJJDLeND"
      },
      "outputs": [],
      "source": [
        "def main():\n",
        "\n",
        "    types = ['vgg19','vgg16']\n",
        "    for tp in types:\n",
        "      print(f\"Model type: {tp}\")\n",
        "      # Build the model\n",
        "      model = build_model(tp)\n",
        "\n",
        "      # Train the model (optional, you can load a pretrained model)\n",
        "      # train = input(\"Do you want to train the model? (y/n): \")\n",
        "      # if train.lower() == 'y':\n",
        "      #     history = train_model(tp,model, train_data_dir, test_data_dir, epochs=2)\n",
        "      # else:\n",
        "      #     # Load pre-trained model (if available)\n",
        "      #     if os.path.exists(f\"model_{tp}.h5\"):\n",
        "      #         model = load_model(\"model_CNN.h5\")\n",
        "      #         print(\"Model loaded successfully.\")\n",
        "      #     else:\n",
        "      #         print(\"No pre-trained model found. You should train the model first.\")\n",
        "      #         return\n",
        "      history = train_model(tp,model, train_data_dir, test_data_dir, epochs=100)\n",
        "\n",
        "      # Evaluate the model on the test set\n",
        "      # evaluate = input(\"Do you want to evaluate the model? (y/n): \")\n",
        "      # if evaluate.lower() == 'y':\n",
        "      evaluate_model(model, test_data_dir, history)\n",
        "\n",
        "      # Run real-time facial expression detection\n",
        "      # run_realtime_choice = input(\"Do you want to run real-time facial expression detection? (y/n): \")\n",
        "      # if run_realtime_choice.lower() == 'y':\n",
        "      #     run_realtime(model)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 100,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "GXR7kiWFLeNE",
        "outputId": "2f790ea7-a848-415c-d990-5b7683c5abd4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model type: vgg19\n",
            "Found 28709 images belonging to 7 classes.\n",
            "Found 7178 images belonging to 7 classes.\n",
            "28709\n",
            "7178\n",
            "Epoch 1/100\n",
            "\u001b[1m897/897\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 50ms/step - accuracy: 0.2715 - loss: 1.7714 - val_accuracy: 0.3228 - val_loss: 1.6980\n",
            "Epoch 2/100\n",
            "\u001b[1m  1/897\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m16s\u001b[0m 18ms/step - accuracy: 0.3750 - loss: 1.5834"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/trainers/epoch_iterator.py:107: UserWarning: Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches. You may need to use the `.repeat()` function when building your dataset.\n",
            "  self._interrupted_warning()\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m897/897\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - accuracy: 0.3750 - loss: 1.5834 - val_accuracy: 0.3218 - val_loss: 1.6978\n",
            "Epoch 3/100\n",
            "\u001b[1m897/897\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m44s\u001b[0m 49ms/step - accuracy: 0.3119 - loss: 1.7035 - val_accuracy: 0.3200 - val_loss: 1.6836\n",
            "Epoch 4/100\n",
            "\u001b[1m897/897\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4ms/step - accuracy: 0.2812 - loss: 1.6434 - val_accuracy: 0.3191 - val_loss: 1.6877\n",
            "Epoch 5/100\n",
            "\u001b[1m897/897\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 92ms/step - accuracy: 0.3183 - loss: 1.6966 - val_accuracy: 0.3205 - val_loss: 1.6836\n",
            "Epoch 6/100\n",
            "\u001b[1m897/897\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - accuracy: 0.3750 - loss: 1.7033 - val_accuracy: 0.3185 - val_loss: 1.6902\n",
            "Epoch 7/100\n",
            "\u001b[1m897/897\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m101s\u001b[0m 51ms/step - accuracy: 0.3216 - loss: 1.6850 - val_accuracy: 0.3496 - val_loss: 1.6338\n",
            "Epoch 8/100\n",
            "\u001b[1m897/897\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4ms/step - accuracy: 0.5312 - loss: 1.5030 - val_accuracy: 0.3474 - val_loss: 1.6356\n",
            "Epoch 9/100\n",
            "\u001b[1m897/897\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m79s\u001b[0m 52ms/step - accuracy: 0.3205 - loss: 1.6734 - val_accuracy: 0.3396 - val_loss: 1.6563\n",
            "Epoch 10/100\n",
            "\u001b[1m897/897\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4ms/step - accuracy: 0.4062 - loss: 1.6406 - val_accuracy: 0.3394 - val_loss: 1.6546\n",
            "Epoch 11/100\n",
            "\u001b[1m897/897\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m77s\u001b[0m 51ms/step - accuracy: 0.3281 - loss: 1.6725 - val_accuracy: 0.3306 - val_loss: 1.6716\n",
            "Epoch 12/100\n",
            "\u001b[1m897/897\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4ms/step - accuracy: 0.3438 - loss: 1.6880 - val_accuracy: 0.3278 - val_loss: 1.6735\n",
            "Epoch 13/100\n",
            "\u001b[1m897/897\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 91ms/step - accuracy: 0.3319 - loss: 1.6646 - val_accuracy: 0.3546 - val_loss: 1.6226\n",
            "Epoch 14/100\n",
            "\u001b[1m897/897\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4ms/step - accuracy: 0.4688 - loss: 1.5541 - val_accuracy: 0.3551 - val_loss: 1.6197\n",
            "Epoch 15/100\n",
            "\u001b[1m897/897\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m101s\u001b[0m 50ms/step - accuracy: 0.3338 - loss: 1.6639 - val_accuracy: 0.3396 - val_loss: 1.6414\n",
            "Epoch 16/100\n",
            "\u001b[1m897/897\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - accuracy: 0.2500 - loss: 1.6511 - val_accuracy: 0.3394 - val_loss: 1.6382\n",
            "Epoch 17/100\n",
            "\u001b[1m897/897\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m77s\u001b[0m 51ms/step - accuracy: 0.3317 - loss: 1.6609 - val_accuracy: 0.3479 - val_loss: 1.6371\n",
            "Epoch 18/100\n",
            "\u001b[1m897/897\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4ms/step - accuracy: 0.2500 - loss: 1.7139 - val_accuracy: 0.3502 - val_loss: 1.6320\n",
            "Epoch 19/100\n",
            "\u001b[1m897/897\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 53ms/step - accuracy: 0.3379 - loss: 1.6556 - val_accuracy: 0.3562 - val_loss: 1.5992\n",
            "Epoch 20/100\n",
            "\u001b[1m897/897\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4ms/step - accuracy: 0.2812 - loss: 1.7709 - val_accuracy: 0.3567 - val_loss: 1.5973\n",
            "Epoch 21/100\n",
            "\u001b[1m897/897\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m45s\u001b[0m 51ms/step - accuracy: 0.3339 - loss: 1.6635 - val_accuracy: 0.3581 - val_loss: 1.6250\n",
            "Epoch 22/100\n",
            "\u001b[1m897/897\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4ms/step - accuracy: 0.3438 - loss: 1.6154 - val_accuracy: 0.3585 - val_loss: 1.6258\n",
            "Epoch 23/100\n",
            "\u001b[1m897/897\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 55ms/step - accuracy: 0.3312 - loss: 1.6600 - val_accuracy: 0.3489 - val_loss: 1.6448\n",
            "Epoch 24/100\n",
            "\u001b[1m897/897\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - accuracy: 0.3750 - loss: 1.6500 - val_accuracy: 0.3495 - val_loss: 1.6429\n",
            "Epoch 25/100\n",
            "\u001b[1m897/897\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 61ms/step - accuracy: 0.3414 - loss: 1.6498 - val_accuracy: 0.3433 - val_loss: 1.6678\n",
            "Epoch 26/100\n",
            "\u001b[1m897/897\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4ms/step - accuracy: 0.2188 - loss: 1.9008 - val_accuracy: 0.3433 - val_loss: 1.6649\n",
            "Epoch 27/100\n",
            "\u001b[1m897/897\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m69s\u001b[0m 51ms/step - accuracy: 0.3384 - loss: 1.6531 - val_accuracy: 0.3612 - val_loss: 1.6043\n",
            "Epoch 28/100\n",
            "\u001b[1m897/897\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - accuracy: 0.4062 - loss: 1.6091 - val_accuracy: 0.3624 - val_loss: 1.6095\n",
            "Epoch 29/100\n",
            "\u001b[1m897/897\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m77s\u001b[0m 52ms/step - accuracy: 0.3462 - loss: 1.6460 - val_accuracy: 0.3624 - val_loss: 1.6148\n",
            "Epoch 30/100\n",
            "\u001b[1m897/897\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 5ms/step - accuracy: 0.3125 - loss: 1.6046 - val_accuracy: 0.3645 - val_loss: 1.6127\n",
            "Epoch 31/100\n",
            "\u001b[1m897/897\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m46s\u001b[0m 51ms/step - accuracy: 0.3406 - loss: 1.6472 - val_accuracy: 0.3569 - val_loss: 1.6132\n",
            "Epoch 32/100\n",
            "\u001b[1m897/897\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4ms/step - accuracy: 0.3750 - loss: 1.5660 - val_accuracy: 0.3544 - val_loss: 1.6161\n",
            "Epoch 33/100\n",
            "\u001b[1m897/897\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 56ms/step - accuracy: 0.3414 - loss: 1.6484 - val_accuracy: 0.3535 - val_loss: 1.6147\n",
            "Epoch 34/100\n",
            "\u001b[1m897/897\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4ms/step - accuracy: 0.4062 - loss: 1.6262 - val_accuracy: 0.3562 - val_loss: 1.6143\n",
            "Epoch 35/100\n",
            "\u001b[1m897/897\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m44s\u001b[0m 49ms/step - accuracy: 0.3376 - loss: 1.6484 - val_accuracy: 0.3580 - val_loss: 1.6082\n",
            "Epoch 36/100\n",
            "\u001b[1m897/897\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4ms/step - accuracy: 0.2812 - loss: 1.6248 - val_accuracy: 0.3585 - val_loss: 1.6090\n",
            "Epoch 37/100\n",
            "\u001b[1m897/897\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 91ms/step - accuracy: 0.3388 - loss: 1.6549 - val_accuracy: 0.3753 - val_loss: 1.5872\n",
            "Epoch 38/100\n",
            "\u001b[1m897/897\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4ms/step - accuracy: 0.2500 - loss: 1.7402 - val_accuracy: 0.3750 - val_loss: 1.5878\n",
            "Epoch 39/100\n",
            "\u001b[1m897/897\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m142s\u001b[0m 96ms/step - accuracy: 0.3360 - loss: 1.6498 - val_accuracy: 0.3535 - val_loss: 1.6129\n",
            "Epoch 40/100\n",
            "\u001b[1m897/897\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4ms/step - accuracy: 0.5312 - loss: 1.4880 - val_accuracy: 0.3525 - val_loss: 1.6137\n",
            "Epoch 41/100\n",
            "\u001b[1m897/897\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m96s\u001b[0m 50ms/step - accuracy: 0.3489 - loss: 1.6373 - val_accuracy: 0.3676 - val_loss: 1.5941\n",
            "Epoch 42/100\n",
            "\u001b[1m897/897\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4ms/step - accuracy: 0.2812 - loss: 1.5793 - val_accuracy: 0.3686 - val_loss: 1.5920\n",
            "Epoch 43/100\n",
            "\u001b[1m897/897\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m44s\u001b[0m 49ms/step - accuracy: 0.3463 - loss: 1.6381 - val_accuracy: 0.3530 - val_loss: 1.6685\n",
            "Epoch 44/100\n",
            "\u001b[1m897/897\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4ms/step - accuracy: 0.3125 - loss: 1.8252 - val_accuracy: 0.3528 - val_loss: 1.6632\n",
            "Epoch 45/100\n",
            "\u001b[1m897/897\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m44s\u001b[0m 49ms/step - accuracy: 0.3512 - loss: 1.6340 - val_accuracy: 0.3680 - val_loss: 1.5911\n",
            "Epoch 46/100\n",
            "\u001b[1m897/897\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - accuracy: 0.4375 - loss: 1.6939 - val_accuracy: 0.3684 - val_loss: 1.5912\n",
            "Epoch 47/100\n",
            "\u001b[1m897/897\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m44s\u001b[0m 50ms/step - accuracy: 0.3448 - loss: 1.6393 - val_accuracy: 0.3704 - val_loss: 1.6171\n",
            "Epoch 48/100\n",
            "\u001b[1m897/897\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4ms/step - accuracy: 0.4375 - loss: 1.5981 - val_accuracy: 0.3701 - val_loss: 1.6180\n",
            "Epoch 49/100\n",
            "\u001b[1m897/897\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m77s\u001b[0m 49ms/step - accuracy: 0.3510 - loss: 1.6226 - val_accuracy: 0.3592 - val_loss: 1.6206\n",
            "Epoch 50/100\n",
            "\u001b[1m897/897\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4ms/step - accuracy: 0.3125 - loss: 1.7911 - val_accuracy: 0.3599 - val_loss: 1.6195\n",
            "Epoch 51/100\n",
            "\u001b[1m897/897\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m83s\u001b[0m 92ms/step - accuracy: 0.3475 - loss: 1.6426 - val_accuracy: 0.3605 - val_loss: 1.6079\n",
            "Epoch 52/100\n",
            "\u001b[1m897/897\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4ms/step - accuracy: 0.3750 - loss: 1.7453 - val_accuracy: 0.3612 - val_loss: 1.6076\n",
            "Epoch 53/100\n",
            "\u001b[1m897/897\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m44s\u001b[0m 49ms/step - accuracy: 0.3477 - loss: 1.6334 - val_accuracy: 0.3708 - val_loss: 1.5906\n",
            "Epoch 54/100\n",
            "\u001b[1m897/897\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4ms/step - accuracy: 0.4062 - loss: 1.5449 - val_accuracy: 0.3693 - val_loss: 1.5919\n",
            "Epoch 55/100\n",
            "\u001b[1m897/897\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 91ms/step - accuracy: 0.3458 - loss: 1.6405 - val_accuracy: 0.3636 - val_loss: 1.6102\n",
            "Epoch 56/100\n",
            "\u001b[1m897/897\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - accuracy: 0.3438 - loss: 1.6205 - val_accuracy: 0.3651 - val_loss: 1.6078\n",
            "Epoch 57/100\n",
            "\u001b[1m897/897\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m142s\u001b[0m 97ms/step - accuracy: 0.3516 - loss: 1.6310 - val_accuracy: 0.3624 - val_loss: 1.6131\n",
            "Epoch 58/100\n",
            "\u001b[1m897/897\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4ms/step - accuracy: 0.3125 - loss: 1.5832 - val_accuracy: 0.3619 - val_loss: 1.6147\n",
            "Epoch 59/100\n",
            "\u001b[1m897/897\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 91ms/step - accuracy: 0.3485 - loss: 1.6301 - val_accuracy: 0.3562 - val_loss: 1.6240\n",
            "Epoch 60/100\n",
            "\u001b[1m897/897\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4ms/step - accuracy: 0.3750 - loss: 1.5635 - val_accuracy: 0.3578 - val_loss: 1.6211\n",
            "Epoch 61/100\n",
            "\u001b[1m897/897\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 48ms/step - accuracy: 0.3504 - loss: 1.6255 - val_accuracy: 0.3630 - val_loss: 1.6001\n",
            "Epoch 62/100\n",
            "\u001b[1m897/897\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4ms/step - accuracy: 0.4375 - loss: 1.5511 - val_accuracy: 0.3631 - val_loss: 1.5985\n",
            "Epoch 63/100\n",
            "\u001b[1m897/897\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 91ms/step - accuracy: 0.3546 - loss: 1.6192 - val_accuracy: 0.3549 - val_loss: 1.6252\n",
            "Epoch 64/100\n",
            "\u001b[1m897/897\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4ms/step - accuracy: 0.3750 - loss: 1.6006 - val_accuracy: 0.3549 - val_loss: 1.6240\n",
            "Epoch 65/100\n",
            "\u001b[1m897/897\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m100s\u001b[0m 49ms/step - accuracy: 0.3459 - loss: 1.6356 - val_accuracy: 0.3615 - val_loss: 1.6170\n",
            "Epoch 66/100\n",
            "\u001b[1m897/897\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4ms/step - accuracy: 0.3750 - loss: 1.7064 - val_accuracy: 0.3602 - val_loss: 1.6180\n",
            "Epoch 67/100\n",
            "\u001b[1m897/897\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m45s\u001b[0m 50ms/step - accuracy: 0.3508 - loss: 1.6232 - val_accuracy: 0.3605 - val_loss: 1.6253\n",
            "Epoch 68/100\n",
            "\u001b[1m897/897\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4ms/step - accuracy: 0.8000 - loss: 1.1896 - val_accuracy: 0.3566 - val_loss: 1.6344\n",
            "Epoch 69/100\n",
            "\u001b[1m897/897\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 91ms/step - accuracy: 0.3590 - loss: 1.6148 - val_accuracy: 0.3696 - val_loss: 1.6062\n",
            "Epoch 70/100\n",
            "\u001b[1m897/897\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4ms/step - accuracy: 0.3750 - loss: 1.5667 - val_accuracy: 0.3686 - val_loss: 1.6057\n",
            "Epoch 71/100\n",
            "\u001b[1m897/897\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 91ms/step - accuracy: 0.3571 - loss: 1.6196 - val_accuracy: 0.3637 - val_loss: 1.6334\n",
            "Epoch 72/100\n",
            "\u001b[1m897/897\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4ms/step - accuracy: 0.3750 - loss: 1.5463 - val_accuracy: 0.3631 - val_loss: 1.6340\n",
            "Epoch 73/100\n",
            "\u001b[1m897/897\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m100s\u001b[0m 49ms/step - accuracy: 0.3569 - loss: 1.6209 - val_accuracy: 0.3743 - val_loss: 1.5982\n",
            "Epoch 74/100\n",
            "\u001b[1m897/897\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4ms/step - accuracy: 0.4375 - loss: 1.4546 - val_accuracy: 0.3744 - val_loss: 1.5966\n",
            "Epoch 75/100\n",
            "\u001b[1m897/897\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 91ms/step - accuracy: 0.3568 - loss: 1.6144 - val_accuracy: 0.3647 - val_loss: 1.5935\n",
            "Epoch 76/100\n",
            "\u001b[1m897/897\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4ms/step - accuracy: 0.1875 - loss: 1.7041 - val_accuracy: 0.3652 - val_loss: 1.5919\n",
            "Epoch 77/100\n",
            "\u001b[1m897/897\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m142s\u001b[0m 96ms/step - accuracy: 0.3526 - loss: 1.6227 - val_accuracy: 0.3598 - val_loss: 1.6100\n",
            "Epoch 78/100\n",
            "\u001b[1m897/897\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4ms/step - accuracy: 0.3750 - loss: 1.6300 - val_accuracy: 0.3605 - val_loss: 1.6081\n",
            "Epoch 79/100\n",
            "\u001b[1m897/897\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 48ms/step - accuracy: 0.3540 - loss: 1.6121 - val_accuracy: 0.3700 - val_loss: 1.5987\n",
            "Epoch 80/100\n",
            "\u001b[1m897/897\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4ms/step - accuracy: 0.3750 - loss: 1.5906 - val_accuracy: 0.3689 - val_loss: 1.6014\n",
            "Epoch 81/100\n",
            "\u001b[1m897/897\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m45s\u001b[0m 50ms/step - accuracy: 0.3576 - loss: 1.6158 - val_accuracy: 0.3744 - val_loss: 1.5912\n",
            "Epoch 82/100\n",
            "\u001b[1m897/897\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - accuracy: 0.4688 - loss: 1.6716 - val_accuracy: 0.3751 - val_loss: 1.5896\n",
            "Epoch 83/100\n",
            "\u001b[1m897/897\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 56ms/step - accuracy: 0.3614 - loss: 1.6192 - val_accuracy: 0.3676 - val_loss: 1.6047\n",
            "Epoch 84/100\n",
            "\u001b[1m897/897\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - accuracy: 0.5000 - loss: 1.4062 - val_accuracy: 0.3677 - val_loss: 1.6040\n",
            "Epoch 85/100\n",
            "\u001b[1m897/897\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m72s\u001b[0m 50ms/step - accuracy: 0.3607 - loss: 1.6188 - val_accuracy: 0.3534 - val_loss: 1.6188\n",
            "Epoch 86/100\n",
            "\u001b[1m897/897\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4ms/step - accuracy: 0.3125 - loss: 1.7255 - val_accuracy: 0.3567 - val_loss: 1.6156\n",
            "Epoch 87/100\n",
            "\u001b[1m897/897\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m77s\u001b[0m 48ms/step - accuracy: 0.3606 - loss: 1.6158 - val_accuracy: 0.3683 - val_loss: 1.5949\n",
            "Epoch 88/100\n",
            "\u001b[1m897/897\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4ms/step - accuracy: 0.4062 - loss: 1.5306 - val_accuracy: 0.3684 - val_loss: 1.5936\n",
            "Epoch 89/100\n",
            "\u001b[1m897/897\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 53ms/step - accuracy: 0.3573 - loss: 1.6191 - val_accuracy: 0.3711 - val_loss: 1.5875\n",
            "Epoch 90/100\n",
            "\u001b[1m897/897\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - accuracy: 0.3125 - loss: 1.5555 - val_accuracy: 0.3717 - val_loss: 1.5891\n",
            "Epoch 91/100\n",
            "\u001b[1m897/897\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 48ms/step - accuracy: 0.3590 - loss: 1.6178 - val_accuracy: 0.3651 - val_loss: 1.6208\n",
            "Epoch 92/100\n",
            "\u001b[1m897/897\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4ms/step - accuracy: 0.3438 - loss: 1.4587 - val_accuracy: 0.3634 - val_loss: 1.6249\n",
            "Epoch 93/100\n",
            "\u001b[1m897/897\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 52ms/step - accuracy: 0.3592 - loss: 1.6207 - val_accuracy: 0.3580 - val_loss: 1.6116\n",
            "Epoch 94/100\n",
            "\u001b[1m897/897\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - accuracy: 0.3750 - loss: 1.6146 - val_accuracy: 0.3571 - val_loss: 1.6138\n",
            "Epoch 95/100\n",
            "\u001b[1m897/897\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m74s\u001b[0m 48ms/step - accuracy: 0.3528 - loss: 1.6253 - val_accuracy: 0.3747 - val_loss: 1.5981\n",
            "Epoch 96/100\n",
            "\u001b[1m897/897\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4ms/step - accuracy: 0.1875 - loss: 1.8747 - val_accuracy: 0.3739 - val_loss: 1.6000\n",
            "Epoch 97/100\n",
            "\u001b[1m897/897\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 91ms/step - accuracy: 0.3548 - loss: 1.6228 - val_accuracy: 0.3574 - val_loss: 1.6306\n",
            "Epoch 98/100\n",
            "\u001b[1m897/897\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4ms/step - accuracy: 0.2188 - loss: 1.7330 - val_accuracy: 0.3573 - val_loss: 1.6289\n",
            "Epoch 99/100\n",
            "\u001b[1m897/897\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m142s\u001b[0m 96ms/step - accuracy: 0.3609 - loss: 1.6108 - val_accuracy: 0.3610 - val_loss: 1.6267\n",
            "Epoch 100/100\n",
            "\u001b[1m897/897\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - accuracy: 0.3438 - loss: 1.6224 - val_accuracy: 0.3624 - val_loss: 1.6224\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "evaluate_model() takes 3 positional arguments but 4 were given",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-100-972361fa1b80>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"__main__\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-99-10637d7f9fe1>\u001b[0m in \u001b[0;36mmain\u001b[0;34m()\u001b[0m\n\u001b[1;32m     24\u001b[0m       \u001b[0;31m# evaluate = input(\"Do you want to evaluate the model? (y/n): \")\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m       \u001b[0;31m# if evaluate.lower() == 'y':\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m       \u001b[0mevaluate_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtp\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_data_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhistory\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     27\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m       \u001b[0;31m# Run real-time facial expression detection\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: evaluate_model() takes 3 positional arguments but 4 were given"
          ]
        }
      ],
      "source": [
        "if __name__ == \"__main__\":\n",
        "    main()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "H2J1ky5fbuMM"
      }
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.10"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}